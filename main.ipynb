{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collect-computer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from modules.Twitter import Twitter\n",
    "import logging\n",
    "import coloredlogs\n",
    "import time\n",
    "import os\n",
    "import pandas as pd\n",
    "from modules.Models import *\n",
    "from modules.NewsHeadLine import NewsHeadLine\n",
    "import yfinance\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "undefined-church",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename=f'{os.getcwd()}/output/logs/{time.strftime(\"%m-%d-%Y %I-%M%p\")}.log',\n",
    "                    encoding='utf-8',\n",
    "                    level=logging.DEBUG,\n",
    "                    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%m/%d/%Y %I:%M:%S %p')\n",
    "coloredlogs.install(fmt='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    datefmt='%m/%d/%Y %I:%M:%S %p',\n",
    "                    level=\"debug\")\n",
    "logging.getLogger('matplotlib').setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- model building --- #\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model helper functions\n",
    "\n",
    "def prediction_to_str(prediction):\n",
    "    '''_summary_\n",
    "\n",
    "    Args:\n",
    "        prediction (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    '''\n",
    "    if isinstance(prediction, list):\n",
    "        prediction = int(prediction[0])\n",
    "    Logger.debug(\"Prediction %s \", prediction)\n",
    "    if prediction == 0:\n",
    "        return \"NEUTRAL\"\n",
    "    elif prediction == 1:\n",
    "        return \"POSITIVE\"\n",
    "    elif prediction == -1:\n",
    "        return \"NEGATIVE\"\n",
    "    else:\n",
    "        return \"N/A\"\n",
    "def prediction_to_color(prediction):\n",
    "    if prediction == 0:\n",
    "        return \"yellow\"\n",
    "    elif prediction == 1:\n",
    "        return \"green\"\n",
    "    elif prediction == -1:\n",
    "        return \"red\"\n",
    "    else:\n",
    "        return \"blue\"\n",
    "    \n",
    "def model_analysis(Y_test, prediction):\n",
    "    '''Display model metrics\n",
    "\n",
    "    Args:\n",
    "        prediction (_type_): _description_\n",
    "    '''\n",
    "    accuracy = accuracy_score(Y_test, prediction)\n",
    "    Logger.debug('Model accuracy score\\n%s', accuracy)\n",
    "\n",
    "    report = classification_report(Y_test, prediction)\n",
    "    Logger.debug('Classification report\\n%s', report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-basketball",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_path = os.getcwd() + \"/input/training_data.csv\"\n",
    "dataframe = pd.read_csv(training_data_path, sep=';', names=['ID', 'Ticker', 'Date', 'Text', 'Sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cosmetic-channel",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-biodiversity",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-contractor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-auckland",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.Sentiment.value_counts().plot(kind=\"pie\",autopct=\"%1.0f%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-flood",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floating-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.Ticker.value_counts().plot(kind=\"pie\",autopct=\"%1.0f%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thrown-sending",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataframe = dataframe.dropna()\n",
    "dataframe.Text = dataframe['Text'].apply(Preprocess.clean_text)\n",
    "dataframe['Sentiment'] = dataframe['Sentiment'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automatic-determination",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataframe['Text'].values\n",
    "Y = dataframe['Sentiment'].values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer()\n",
    "vector.fit(X_train)\n",
    "\n",
    "X_train = vector.transform(X_train)\n",
    "X_test = vector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regulation-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model selection; cross validation and hyper parameter tuning\n",
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.LinearSVC(max_iter=10000),\n",
    "        'params': {\n",
    "            'C': [1, 10, 20],\n",
    "        }\n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'n_estimators': [1, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression': {\n",
    "        'model': LogisticRegression(max_iter=10000),\n",
    "        'params': {\n",
    "            'C': [1, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'gradient_boost':{\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params':{\n",
    "            'n_estimators': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "\n",
    "}\n",
    "scores = []\n",
    "for model_name, mp in model_params.items():\n",
    "    clf = GridSearchCV(mp['model'], mp['params'],\n",
    "                       cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    scores.append({\n",
    "        'model': model_name,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "model_selection = pd.DataFrame(scores, columns=['model', 'best_score', 'best_params'])\n",
    "model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extraordinary-basis",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = svm.LinearSVC(max_iter=1000, C=1)\n",
    "model.fit(X_train, Y_train)\n",
    "model_str = \"Linear Support vector Machine\"\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earlier-blair",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prompt-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-linux",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(confusion_matrix(Y_test, predictions))\n",
    "sns.heatmap(confusion_matrix(Y_test, predictions), annot=True, fmt='g')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "altered-inspector",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(data):\n",
    "    data_vector = vector.transform([data])\n",
    "    prediction = model.predict(data_vector)\n",
    "    Logger.debug(\"Classification using %s for '%s' is %s\",\n",
    "                 model_str,\n",
    "                 data,\n",
    "                 prediction_to_str(prediction))\n",
    "\n",
    "    Logger.debug(\"Classification using sentiment analyzer for '%s' is %s\",\n",
    "                 data,\n",
    "                 SENTIMENT_ANALYZER.polarity_scores(data))\n",
    "\n",
    "    return prediction\n",
    "classify(\"AMAZON is the worst\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_seconds(d1, d2):\n",
    "    d1 = datetime.strptime(d1, \"%Y-%m-%d %H:%M:%S\")\n",
    "    d2 = datetime.strptime(d2, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return abs((d2 - d1).seconds)\n",
    "def is_same_day(d1, d2):\n",
    "    d1 = datetime.strptime(d1, \"%Y-%m-%d %H:%M:%S\")\n",
    "    d2 = datetime.strptime(d2, \"%Y-%m-%d %H:%M:%S\")\n",
    "    return abs((d2 - d1).days) == 0\n",
    "def get_financial_data(tickers, period, interval):\n",
    "    return yfinance.download(tickers=tickers, period=period, interval=interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-floor",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import ast\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7.5,13)\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# plot financial data\n",
    "\n",
    "financial_data = get_financial_data(\"TSLA\", \"3d\", \"30m\")\n",
    "\n",
    "datetimes = []\n",
    "pricing = []\n",
    "\n",
    "for key,value in json.loads(financial_data.Open.to_json(date_format='iso')).items():\n",
    "    parsed = key.split(\"T\")\n",
    "    timestamp = parsed[0] + \" \" + parsed[1].split(\".\")[0]\n",
    "    datetimes.append(timestamp)\n",
    "    pricing.append(value)\n",
    "    \n",
    "plt.plot(datetimes, pricing, color=\"green\")\n",
    "plt.xticks(datetimes, rotation=80)\n",
    "plt.ylabel(\"Stock price\")\n",
    "plt.xlabel(\"Date timestamp\")\n",
    "plt.title(f\"Price fluctuation of Tesla ($TSLA)\")\n",
    "plt.show()\n",
    "\n",
    "# plot sentiment\n",
    "data = {}\n",
    "for currdate in datetimes:\n",
    "    data[currdate] = {1: 0, -1: 0, 0: 0}\n",
    "for row in ast.literal_eval(dataframe[dataframe['Ticker'].str.contains(\"TSLA\", na=False)].to_json(orient = 'records', date_format='iso')):\n",
    "    post_date = row[\"Date\"]\n",
    "    sentiment = int(row[\"Sentiment\"])\n",
    "    \n",
    "    for key,val in data.items():\n",
    "        if is_same_day(post_date, key) and divmod(diff_seconds(post_date, key),60)[0] <= 15:\n",
    "            val[sentiment] += 1\n",
    "\n",
    "for i in range(-1, 2):\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    for key,val in data.items():\n",
    "        x_arr.append(key)\n",
    "        y_arr.append(val[i])\n",
    "    plt.plot(x_arr,y_arr,label=f\"{prediction_to_str(i)}\", color=prediction_to_color(i))\n",
    "plt.xticks(datetimes, rotation=80)\n",
    "plt.ylabel(\"Amount of posts\")\n",
    "plt.xlabel(\"Date timestamp\")\n",
    "plt.title(f\"Online posts related to $TSLA\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-leeds",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import time\n",
    "import ast\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7.5,13)\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "# plot financial data\n",
    "\n",
    "financial_data = get_financial_data(\"TSLA\", \"7d\", \"30m\")\n",
    "\n",
    "datetimes = []\n",
    "pricing = []\n",
    "\n",
    "for key,value in json.loads(financial_data.Open.to_json(date_format='iso')).items():\n",
    "    parsed = key.split(\"T\")\n",
    "    timestamp = parsed[0] + \" \" + parsed[1].split(\".\")[0]\n",
    "    datetimes.append(timestamp)\n",
    "    pricing.append(value)\n",
    "    \n",
    "plt.plot(datetimes, pricing, color=\"green\")\n",
    "plt.xticks(datetimes, rotation=80)\n",
    "plt.ylabel(\"Stock price\")\n",
    "plt.xlabel(\"Date timestamp\")\n",
    "plt.title(f\"Price fluctuation of Tesla ($TSLA)\")\n",
    "plt.show()\n",
    "\n",
    "# plot sentiment\n",
    "data = {}\n",
    "for currdate in datetimes:\n",
    "    data[currdate] = {1: 0, -1: 0, 0: 0}\n",
    "for row in ast.literal_eval(dataframe[dataframe['Ticker'].str.contains(\"TSLA\", na=False)].to_json(orient = 'records', date_format='iso')):\n",
    "    post_date = row[\"Date\"]\n",
    "    sentiment = int(row[\"Sentiment\"])\n",
    "    \n",
    "    for key,val in data.items():\n",
    "        if is_same_day(post_date, key) and divmod(diff_seconds(post_date, key),60)[0] <= 15:\n",
    "            val[sentiment] += 1\n",
    "\n",
    "for i in range(-1, 2):\n",
    "    x_arr = []\n",
    "    y_arr = []\n",
    "    for key,val in data.items():\n",
    "        x_arr.append(key)\n",
    "        y_arr.append(val[i])\n",
    "    plt.plot(x_arr,y_arr,label=f\"{prediction_to_str(i)}\", color=prediction_to_color(i))\n",
    "plt.xticks(datetimes, rotation=80)\n",
    "plt.ylabel(\"Amount of posts\")\n",
    "plt.xlabel(\"Date timestamp\")\n",
    "plt.title(f\"Online posts related to $TSLA\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-prize",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "94f327eebb2092eba633751f22e3f9ab6153432ecaf401b26a9cc10f4ac5bca8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
